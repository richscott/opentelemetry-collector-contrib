// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver/receivertest"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest/observer"
)

type testDataSet int

const (
	testDataSetDefault testDataSet = iota
	testDataSetAll
	testDataSetNone
	testDataSetReag
)

func TestMetricsBuilder(t *testing.T) {
	tests := []struct {
		name        string
		metricsSet  testDataSet
		resAttrsSet testDataSet
		expectEmpty bool
	}{
		{
			name: "default",
		},
		{
			name:        "all_set",
			metricsSet:  testDataSetAll,
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "reaggregate_set",
			metricsSet:  testDataSetReag,
			resAttrsSet: testDataSetReag,
		},
		{
			name:        "none_set",
			metricsSet:  testDataSetNone,
			resAttrsSet: testDataSetNone,
			expectEmpty: true,
		},
		{
			name:        "filter_set_include",
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "filter_set_exclude",
			resAttrsSet: testDataSetAll,
			expectEmpty: true,
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := pcommon.Timestamp(1_000_000_000)
			ts := pcommon.Timestamp(1_000_001_000)
			observedZapCore, observedLogs := observer.New(zap.WarnLevel)
			settings := receivertest.NewNopSettings(receivertest.NopType)
			settings.Logger = zap.New(observedZapCore)
			mb := NewMetricsBuilder(loadMetricsBuilderConfig(t, tt.name), settings, WithStartTime(start))
			aggMap := make(map[string]string) // contains the aggregation strategies for each metric name
			aggMap["ApacheConnectionsAsync"] = mb.metricApacheConnectionsAsync.config.AggregationStrategy
			aggMap["ApacheCPULoad"] = mb.metricApacheCPULoad.config.AggregationStrategy
			aggMap["ApacheCPUTime"] = mb.metricApacheCPUTime.config.AggregationStrategy
			aggMap["ApacheCurrentConnections"] = mb.metricApacheCurrentConnections.config.AggregationStrategy
			aggMap["ApacheLoad1"] = mb.metricApacheLoad1.config.AggregationStrategy
			aggMap["ApacheLoad15"] = mb.metricApacheLoad15.config.AggregationStrategy
			aggMap["ApacheLoad5"] = mb.metricApacheLoad5.config.AggregationStrategy
			aggMap["ApacheRequestTime"] = mb.metricApacheRequestTime.config.AggregationStrategy
			aggMap["ApacheRequests"] = mb.metricApacheRequests.config.AggregationStrategy
			aggMap["ApacheScoreboard"] = mb.metricApacheScoreboard.config.AggregationStrategy
			aggMap["ApacheTraffic"] = mb.metricApacheTraffic.config.AggregationStrategy
			aggMap["ApacheUptime"] = mb.metricApacheUptime.config.AggregationStrategy
			aggMap["ApacheWorkers"] = mb.metricApacheWorkers.config.AggregationStrategy

			expectedWarnings := 0
			if tt.metricsSet != testDataSetReag {
				assert.Equal(t, expectedWarnings, observedLogs.Len())
			}

			defaultMetricsCount := 0
			allMetricsCount := 0

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheConnectionsAsyncDataPoint(ts, "1", AttributeConnectionStateWriting)
			if tt.name == "reaggregate_set" {
				mb.RecordApacheConnectionsAsyncDataPoint(ts, "3", AttributeConnectionStateKeepalive)
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheCPULoadDataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheCPULoadDataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheCPUTimeDataPoint(ts, "1", AttributeCPULevelSelf, AttributeCPUModeSystem)
			if tt.name == "reaggregate_set" {
				mb.RecordApacheCPUTimeDataPoint(ts, "3", AttributeCPULevelChildren, AttributeCPUModeUser)
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheCurrentConnectionsDataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheCurrentConnectionsDataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheLoad1DataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheLoad1DataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheLoad15DataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheLoad15DataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheLoad5DataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheLoad5DataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheRequestTimeDataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheRequestTimeDataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheRequestsDataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheRequestsDataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheScoreboardDataPoint(ts, 1, AttributeScoreboardStateOpen)
			if tt.name == "reaggregate_set" {
				mb.RecordApacheScoreboardDataPoint(ts, 3, AttributeScoreboardStateWaiting)
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheTrafficDataPoint(ts, 1)
			if tt.name == "reaggregate_set" {
				mb.RecordApacheTrafficDataPoint(ts, 3)
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheUptimeDataPoint(ts, "1")
			if tt.name == "reaggregate_set" {
				mb.RecordApacheUptimeDataPoint(ts, "3")
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordApacheWorkersDataPoint(ts, "1", AttributeWorkersStateBusy)
			if tt.name == "reaggregate_set" {
				mb.RecordApacheWorkersDataPoint(ts, "3", AttributeWorkersStateIdle)
			}

			rb := mb.NewResourceBuilder()
			rb.SetApacheServerName("apache.server.name-val")
			rb.SetApacheServerPort("apache.server.port-val")
			res := rb.Emit()
			metrics := mb.Emit(WithResource(res))
			if tt.name == "reaggregate_set" {
				assert.Empty(t, mb.metricApacheConnectionsAsync.aggDataPoints)
				assert.Empty(t, mb.metricApacheCPULoad.aggDataPoints)
				assert.Empty(t, mb.metricApacheCPUTime.aggDataPoints)
				assert.Empty(t, mb.metricApacheCurrentConnections.aggDataPoints)
				assert.Empty(t, mb.metricApacheLoad1.aggDataPoints)
				assert.Empty(t, mb.metricApacheLoad15.aggDataPoints)
				assert.Empty(t, mb.metricApacheLoad5.aggDataPoints)
				assert.Empty(t, mb.metricApacheRequestTime.aggDataPoints)
				assert.Empty(t, mb.metricApacheRequests.aggDataPoints)
				assert.Empty(t, mb.metricApacheScoreboard.aggDataPoints)
				assert.Empty(t, mb.metricApacheTraffic.aggDataPoints)
				assert.Empty(t, mb.metricApacheUptime.aggDataPoints)
				assert.Empty(t, mb.metricApacheWorkers.aggDataPoints)
			}

			if tt.expectEmpty {
				assert.Equal(t, 0, metrics.ResourceMetrics().Len())
				return
			}

			assert.Equal(t, 1, metrics.ResourceMetrics().Len())
			rm := metrics.ResourceMetrics().At(0)
			assert.Equal(t, res, rm.Resource())
			assert.Equal(t, 1, rm.ScopeMetrics().Len())
			ms := rm.ScopeMetrics().At(0).Metrics()
			if tt.metricsSet == testDataSetDefault {
				assert.Equal(t, defaultMetricsCount, ms.Len())
			}
			if tt.metricsSet == testDataSetAll {
				assert.Equal(t, allMetricsCount, ms.Len())
			}
			validatedMetrics := make(map[string]bool)
			for i := 0; i < ms.Len(); i++ {
				switch ms.At(i).Name() {
				case "apache.connections.async":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.connections.async"], "Found a duplicate in the metrics slice: apache.connections.async")
						validatedMetrics["apache.connections.async"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The number of connections in different asynchronous states reported by Apache's server-status.", ms.At(i).Description())
						assert.Equal(t, "{connections}", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
						attrVal, ok := dp.Attributes().Get("connection_state")
						assert.True(t, ok)
						assert.Equal(t, "writing", attrVal.Str())
					} else {
						assert.False(t, validatedMetrics["apache.connections.async"], "Found a duplicate in the metrics slice: apache.connections.async")
						validatedMetrics["apache.connections.async"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The number of connections in different asynchronous states reported by Apache's server-status.", ms.At(i).Description())
						assert.Equal(t, "{connections}", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.connections.async"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
						_, ok := dp.Attributes().Get("connection_state")
						assert.False(t, ok)
					}
				case "apache.cpu.load":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.cpu.load"], "Found a duplicate in the metrics slice: apache.cpu.load")
						validatedMetrics["apache.cpu.load"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "Current load of the CPU.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					} else {
						assert.False(t, validatedMetrics["apache.cpu.load"], "Found a duplicate in the metrics slice: apache.cpu.load")
						validatedMetrics["apache.cpu.load"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "Current load of the CPU.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["apache.cpu.load"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
					}
				case "apache.cpu.time":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.cpu.time"], "Found a duplicate in the metrics slice: apache.cpu.time")
						validatedMetrics["apache.cpu.time"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Jiffs used by processes of given category.", ms.At(i).Description())
						assert.Equal(t, "{jiff}", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						attrVal, ok := dp.Attributes().Get("level")
						assert.True(t, ok)
						assert.Equal(t, "self", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("mode")
						assert.True(t, ok)
						assert.Equal(t, "system", attrVal.Str())
					} else {
						assert.False(t, validatedMetrics["apache.cpu.time"], "Found a duplicate in the metrics slice: apache.cpu.time")
						validatedMetrics["apache.cpu.time"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Jiffs used by processes of given category.", ms.At(i).Description())
						assert.Equal(t, "{jiff}", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["apache.cpu.time"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
						_, ok := dp.Attributes().Get("level")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("mode")
						assert.False(t, ok)
					}
				case "apache.current_connections":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.current_connections"], "Found a duplicate in the metrics slice: apache.current_connections")
						validatedMetrics["apache.current_connections"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of active connections currently attached to the HTTP server.", ms.At(i).Description())
						assert.Equal(t, "{connections}", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
					} else {
						assert.False(t, validatedMetrics["apache.current_connections"], "Found a duplicate in the metrics slice: apache.current_connections")
						validatedMetrics["apache.current_connections"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of active connections currently attached to the HTTP server.", ms.At(i).Description())
						assert.Equal(t, "{connections}", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.current_connections"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
					}
				case "apache.load.1":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.load.1"], "Found a duplicate in the metrics slice: apache.load.1")
						validatedMetrics["apache.load.1"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The average server load during the last minute.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					} else {
						assert.False(t, validatedMetrics["apache.load.1"], "Found a duplicate in the metrics slice: apache.load.1")
						validatedMetrics["apache.load.1"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The average server load during the last minute.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["apache.load.1"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
					}
				case "apache.load.15":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.load.15"], "Found a duplicate in the metrics slice: apache.load.15")
						validatedMetrics["apache.load.15"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The average server load during the last 15 minutes.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					} else {
						assert.False(t, validatedMetrics["apache.load.15"], "Found a duplicate in the metrics slice: apache.load.15")
						validatedMetrics["apache.load.15"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The average server load during the last 15 minutes.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["apache.load.15"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
					}
				case "apache.load.5":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.load.5"], "Found a duplicate in the metrics slice: apache.load.5")
						validatedMetrics["apache.load.5"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The average server load during the last 5 minutes.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					} else {
						assert.False(t, validatedMetrics["apache.load.5"], "Found a duplicate in the metrics slice: apache.load.5")
						validatedMetrics["apache.load.5"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "The average server load during the last 5 minutes.", ms.At(i).Description())
						assert.Equal(t, "%", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["apache.load.5"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
					}
				case "apache.request.time":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.request.time"], "Found a duplicate in the metrics slice: apache.request.time")
						validatedMetrics["apache.request.time"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Total time spent on handling requests.", ms.At(i).Description())
						assert.Equal(t, "ms", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
					} else {
						assert.False(t, validatedMetrics["apache.request.time"], "Found a duplicate in the metrics slice: apache.request.time")
						validatedMetrics["apache.request.time"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Total time spent on handling requests.", ms.At(i).Description())
						assert.Equal(t, "ms", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.request.time"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
					}
				case "apache.requests":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.requests"], "Found a duplicate in the metrics slice: apache.requests")
						validatedMetrics["apache.requests"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of requests serviced by the HTTP server per second.", ms.At(i).Description())
						assert.Equal(t, "{requests}", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
					} else {
						assert.False(t, validatedMetrics["apache.requests"], "Found a duplicate in the metrics slice: apache.requests")
						validatedMetrics["apache.requests"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of requests serviced by the HTTP server per second.", ms.At(i).Description())
						assert.Equal(t, "{requests}", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.requests"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
					}
				case "apache.scoreboard":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.scoreboard"], "Found a duplicate in the metrics slice: apache.scoreboard")
						validatedMetrics["apache.scoreboard"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of workers in each state.", ms.At(i).Description())
						assert.Equal(t, "{workers}", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
						attrVal, ok := dp.Attributes().Get("state")
						assert.True(t, ok)
						assert.Equal(t, "open", attrVal.Str())
					} else {
						assert.False(t, validatedMetrics["apache.scoreboard"], "Found a duplicate in the metrics slice: apache.scoreboard")
						validatedMetrics["apache.scoreboard"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of workers in each state.", ms.At(i).Description())
						assert.Equal(t, "{workers}", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.scoreboard"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
						_, ok := dp.Attributes().Get("state")
						assert.False(t, ok)
					}
				case "apache.traffic":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.traffic"], "Found a duplicate in the metrics slice: apache.traffic")
						validatedMetrics["apache.traffic"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Total HTTP server traffic.", ms.At(i).Description())
						assert.Equal(t, "By", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
					} else {
						assert.False(t, validatedMetrics["apache.traffic"], "Found a duplicate in the metrics slice: apache.traffic")
						validatedMetrics["apache.traffic"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Total HTTP server traffic.", ms.At(i).Description())
						assert.Equal(t, "By", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.traffic"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
					}
				case "apache.uptime":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.uptime"], "Found a duplicate in the metrics slice: apache.uptime")
						validatedMetrics["apache.uptime"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The amount of time that the server has been running in seconds.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
					} else {
						assert.False(t, validatedMetrics["apache.uptime"], "Found a duplicate in the metrics slice: apache.uptime")
						validatedMetrics["apache.uptime"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The amount of time that the server has been running in seconds.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.uptime"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
					}
				case "apache.workers":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["apache.workers"], "Found a duplicate in the metrics slice: apache.workers")
						validatedMetrics["apache.workers"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of workers currently attached to the HTTP server.", ms.At(i).Description())
						assert.Equal(t, "{workers}", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
						attrVal, ok := dp.Attributes().Get("state")
						assert.True(t, ok)
						assert.Equal(t, "busy", attrVal.Str())
					} else {
						assert.False(t, validatedMetrics["apache.workers"], "Found a duplicate in the metrics slice: apache.workers")
						validatedMetrics["apache.workers"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "The number of workers currently attached to the HTTP server.", ms.At(i).Description())
						assert.Equal(t, "{workers}", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["apache.workers"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
						_, ok := dp.Attributes().Get("state")
						assert.False(t, ok)
					}
				}
			}
		})
	}
}
